# Introduction

papaja is short for 'preparing APA journal articles' and is the name of this R package designed to create fully reproducible journal articles that seamlessly fuse statistical analyses, simulations, and prose.
A manuscript written with `papaja` can be thought of as an extensively commented analysis script ready for publication in a scientific journal.


## Motivation

APA style is one of the major style regimes in academia concerned with written scientific communication and is defined in the *Publication Manual of the American Psychological Association* [APA; @american_psychological_association_publication_2010].
Research in psychology and many fields other, including other social sciences, medicine, and public health is reported in APA style.
If you want to publish psychological research, you will have to produce properly formatted APA style manuscripts.
While the merits of standardizing scientific reporting are undisputed, mastering the currently 272 pages of Publication Manual's style definitions puts an undeniable burden on authors.
To simplify the writing process researchers have developed strategies to automate the implementation of APA style.

The dominant approach to writing scientific reports in psychology is the use of common word processors such as Microsoft Word or Libre Office.
Available APA style document templates set up page margins, line spacing, fonts, and related aspects of the manuscript.
The format of citations and references can be automated by using references managers that integrate with the word processor, such as [Zotero](https://www.zotero.org/).

Far less common in psychology, is the use of markup systems, such as [LaTeX](https://en.wikipedia.org/wiki/LaTeX) or [Markdown](https://en.wikipedia.org/wiki/Markdown).
A key concept of markup systems is to separate style from content by means of document annotations.
These annotations declare portions of text for example as title, section headings, or list items but, crucially, they are agnostic to what this means visually (e.g., `<emphasize>text</emphasize>` instead of *text*).
There are several advantages to this approach but, crucially for the present purpose, markup systems compile plain text files to produce the final document.
Critically, the compilation process is required for fully reproducible scientific reports.

### Reproducible scientific reports

Dynamic scientific reports fuse prose and simulation or analysis scripts [@R-knitr; @gandrud_reproducible_2013].
Each time a dynamic document is compiled, the scripts are executed anew and the results---statistics, tables, and figures---are recreated and inserted into the document.
Thereby dynamic documents allow automated reporting of results, which is currently not possible with the prevalent use of Microsoft Word or Libre Office.
Importantly, dynamic documents ensure that the results reported in the manuscript are free of rounding or transcription errors and correspond to the performed analyses.
This is the reason why dynamic scientific reports are commonly referred to as reproducible scientific reports or reproducible reports.
Thus, the term reproducibility here means that given a dataset and analysis script any analyst obtains the same statistical results [@asendorpf_recommendations_2013; @cacioppo_social_2015].

The importance of reproducibility was pinpointed by the U.S. National Science Foundation subcommittee on replicability in science:

> Reproducibility is a minimum necessary condition for a finding to be believable and informative. [p. 4, @cacioppo_social_2015]


> Good statistical practice is fundamentally based on transparent assumptions, repro-ducible results, and valid interpretations.

> The ethical statistician [...] strives to promote transparency in design, execution, and reporting or presenting of all analyses

> Makes documentation suitable for replicate analyses, metadata studies, and other research by qualified investigators.

http://www.amstat.org/asa/files/pdfs/EthicalGuidelines.pdf


“an article about a computational result is advertising, not scholarship. The actual scholarship is the full software environment, code and data, that produced the result.”  - Buckheit & Donoho, 1995


(Elsevier executable paper challenge: 10.1016/j.procs.2011.04.064)

Donoho, D. L., Maleki, A., Rahman, I. U., Shahram, M. & Stodden, V. Reproducible
research in computational harmonic analysis. Comput. Sci. Eng. 11, 8–18 (2009).
Donoho and fellow researchers have been at the forefront of reproducibility for
many years; this a


org-mode: http://www.sciencedirect.com/science/article/pii/S0928425711000374?via%3Dihub
http://yuyang0.github.io/static/doc/babel.pdf

Proprietary software also exists like Inference for R29 – for using R with Microsoft Office – but we do not have any experience with them. Open-source tools like Dexy30 and Sumatra31 are clearly very promising and have capabilities similar to Sweave and org-mode. 


<!-- 1. Generalizability (e.g., Baribault et al., 2017; Brandt et al., 2014) -->
<!-- 2. Replicability (e.g., Open Science Collaboration, 2015; Simons, 2014) -->
<!-- 3. Analytical robustness (e.g., Silberzahn et al., 2017; Simonsohn, Simmons, & Nelson, 2015; Steegen, Tuerlinckx, Gelman, & Vanpaemel, 2016) -->
<!-- 4. Computational reproducibility (e.g., Peng, 2011; Rokem, Marwick, & Staneva, 2017; Stodden, 2015) -->

<!-- <small>But see, for example, Plesser (2018)</small> -->


<!-- U.S. National Science Foundation (NSF) subcommittee on replicability in science: -->

<!-- > [Computational] Reproducibility is a .highlight[minimum necessary condition for a finding to be believable and informative]. (p. 4, Cacioppo, Kaplan, Krosnick, Olds, & Dean, 2015) -->

<!-- &nbsp; -->

<!-- > It is .highlight[scientifically and ethically imperative] that the results of statistical analysis […] be computationally reproducible (p. 138, Liu & Pounds, 2014) -->


<!-- statcheck estimates may be somewhat inaccurate (e.g., Schmidt, 2016) -->

<!-- - Corrections for multiple comparisons -->
<!-- - Sphericity corrections -->
<!-- - Misinterpretation of reported statistics<br />(e.g., bootstrap $p$-values) -->
<!-- - One-tailed test in "wrong" direction -->
<!-- - Misses some reported results (e.g., tables) -->
<!-- - Many undetectable sources of errors -->

<!-- *The problem may even be underestimated!* -->

<!-- Granularity-Related Inconsistency of Means<br />(GRIM, Brown & Heathers, 2016) -->

<!-- - Descriptives of integer data cannot take arbitrary values -->
<!-- - 50% of tested articles contained at least one inconsistency -->
<!-- <!-- - Many inconsistencies arose from incorrectly reported _n_ --> -->

<!-- >  descriptives had been calculated using a Microsoft Excel formula that included an incorrect selection of cells; for example, this resulted in the .highlight[mean and SD of the first experimental condition being included as data points] in the calculation of the mean and SD (p. 4, Brown & Heathers, 2016) -->

<!-- Errors in single-mediator models regression analyses (Petrocelli, Clarkson, Whitmire, & Moon, 2013) -->

<!-- > More than 24% of the 156 models coded failed an equivalence test (i.e., $ab = c – c'$) -->


<!-- _Computational reproducibility is hard!_ -->

<!-- -- -->

<!-- _Quarterly Journal of Political Science_ requires "replication packages" (data and analysis code) upon submission -->

<!-- > 14 of the 24 empirical papers subject to in-house review were found to have discrepancies between the results generated by authors’ own code and those in their written manuscripts. […] .highlight[13 had code that would not execute without errors, eight failed to include code for results] that appeared in the paper (pp. 273-274, Eubank, 2016) -->

<!-- Similar rates have been found in economics journals -->

<!-- > [using] the author-provided data and code files to produce the key qualitative conclusions […] .highlight[we were able to replicate less than half of the papers] [...] .highlight[even with help from the authors] (Chang & Li, 2018) -->

<!-- -- -->

<!-- and in _Science_ publications -->

<!-- > we were able to obtain artifacts from 44% of our sample and were able to .highlight[reproduce the findings for 26%] (Stodden, Seiler, & Ma, 2018). -->


<!-- - wastes resources -->

<!-- > there may have been an .highlight[error in the statistics reported] in the original article […] the .highlight[standard deviations] reported in a similar study (Srull & Wyer, 1980) were .highlight[approximately 6 times as large] (McCarthy et al., in press; multilab replication, $N = 7,373;~k = 22$ labs) -->


<!-- > _Psychological Science_ uses StatCheck […] on manuscripts that are sent out for extended review -->



<!-- Computational reproducibility -->


<!-- - requires precise knowledge of the analytical procedure -->
<!-- - is facilitated by sharing data, analysis scripts, and documentation -->
<!--     - Little appreciated extra work -->
<!--     - Ideally documentation should be a natural by-product -->

<!-- -- -->

<!-- > Your closest collaborator is you six months ago, but you don’t reply to emails. -->

<!-- > &mdash; Paul Wilson, University of Wisconsin Madison -->



<!-- A partial solution to the challenge of computational reproducibilty -->

<!-- - Derived from the concept of literate programming<br />(Knuth, 1992) -->
<!-- - Fuse computer code and documentation -->
<!--     - Fully documented analysis protocols -->
<!--     - Results are embedded directly into the document -->


<!-- A _partial_ solution to the challenge of computational reproducibilty -->

<!-- - Same data, same code, same results -->
<!--     - Prevents transcription errors -->
<!--     - Ensures that statistics, tables, and figures represent the current analytical approach -->
<!-- - Facilitates sharing "replication packages" (Eubank, 2016) -->
<!-- - Increases scientific transparency -->
<!-- - _Cannot guarantee that reported results are correct!_ -->

<!-- ### [Error in one line of code sinks cancer study](http://retractionwatch.com/2016/09/26/error-in-one-line-of-code-sinks-2016-seer-cancer-study/) -->

<!-- > the authors discovered an error in one line of code in the computer program used to calculate the results […]. Specifically, the error assigned the code “unknown” to the additional variables […] the breast cancer death rate ratio […] was given in the original Table 3 as 1.32 (95% CI, 1.28 to 1.36), but in the corrected version it is now 0.89 (95% CI, 0.86 to 0.93) […]. -->


<!-- ### [Boys will be boys: Data error prompts U-turn on study of sex differences in school](http://retractionwatch.com/2017/10/17/boys-will-boys-data-error-prompts-u-turn-study-sex-differences-school/) -->

<!-- > a major error forced the authors to change the title of their paper from “Boys have caught up” to “Boys have not caught up” -->

<!-- The authors discovered that -->

<!-- > there had been a .highlight[systematic coding error during data entry] (the 0/1 coding for “boy” and “girl” that we had on the paper questionnaires was opposite to the one in the SPSS labels). -->



<!-- Wide range of available packages for different languages and output formats -->

<!-- - `Sweave` -->
<!-- - [`rmarkdown`](https://rmarkdown.rstudio.com/) / [`knitr`](https://yihui.name/knitr/) -->
<!-- - [StatTag](http://sites.northwestern.edu/stattag/) -->
<!-- - [Jupyter](http://jupyter.org/) -->
<!-- - [`org-mode`](http://orgmode.org/) -->
<!-- - ... -->


<!-- `rmarkdown` / `knitr` -->

<!-- - Wide support in the R community -->
<!-- - Well integrated with RStudio -->
<!-- - Supports multiple output formats<br />(e.g., HTML, PDF, Microsoft Word) -->
<!-- - Flexible and user friendly -->






<!--

http://www.ncbi.nlm.nih.gov/pubmed/24886202
Bakker, M. & Wicherts, J. M. (2011). The (mis)reporting of statistical results in psychology journals. Behavior Research Methods, 43, 666-678.
	"18% of statistical results in the psychological literature are incorrectly reported [...]  around 15% of the articles contained at least one statistical conclusion that proved, upon recalculation, to be incorrect"

The Prevalence of Statistical Reporting Errors in Psychology (1985-2013)
https://osf.io/e9qbp/

Study: 31 emailed requests for data to replicate SEMs yield 4 positive answers (87% non-reps)
http://t.co/gClUQgoKtL http://t.co/88l0eUJIbf

Statistical Reporting Errors and Collaboration on Statistical Analyses in Psychological Science
http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0114876


49% of econ paper results were successfully reproduced with original data and code, and help from original authors: http://t.co/13UUbwaD8x


Of the subset of articles that were amenable to testing with the GRIM technique (N = 71), around half (N = 36; 50.7%) appeared to contain at least one reported mean inconsistent with the reported sample sizes and scale characteristics, and more than 20% (N = 16) contained multiple such inconsistencies. We requested the data sets corresponding to 21 of these articles, receiving positive responses in 9 cases. We were able to confirm the presence of at least one reporting error in all cases, with 2 articles requiring extensive corrections.
https://peerj.com/preprints/2064/



http://www.plosmedicine.org/article/info:doi/10.1371/journal.pmed.1001747
http://biostatistics.oxfordjournals.org/content/11/3/385.full
http://www.r-bloggers.com/translate2r-migrate-spss-scripts-to-r-at-the-push-of-a-button/

http://osc.centerforopenscience.org/2014/10/30/reproducible-reporting/


Fanelli D (2013) Only reporting guidelines can save (soft) science. European Journal of Personality 27(2): 124
	"Good research practices notwithstanding, therefore, the keys to good science are good reporting practices, which, interestingly, are much easier to ensure. Indeed, reporting guidelines are rapidly being adopted in biomedical and clinical research, where initiatives such as the EQUATOR Network (http://www.equator-network.org) and Minimum Information about a Biomedical or Biological Investigation (http://mibbi.sourceforge.net) publish updated lists of details that authors need to provide, depending on what methodology they used. Major journals have adopted these guidelines spontaneously because doing so improves their reputation. If authors do not comply, their papers are rejected."


More references: http://de.scribd.com/doc/71234390/The-Joy-of-Sweave-A-Beginner-s-Guide-to-Reproducible-Research-with-Sweave


The first article about #APAStyle was published in the Feb 1929 issue of Psychological Bulletin! #TBT @apa_journals http://t.co/1e5CMBqfv8

Willingness to Share Research Data Is Related to the Strength of the Evidence and the Quality of Reporting of Statistical Results
http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0026828


Sharing Detailed Research Data Is Associated with Increased Citation Rate
http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0000308



A first complication is conceptual, because arguably little benefit accrues if another researcher simply clicks “go” or “run” and produces the same numbers from the same data and source code as a previous researcher. Arguably, more would be gained by an independent re-analysis, whereby the second analyst seeks to reproduce the reported results from the raw data and without being guided (and potentially misled) by the first analyst’s code. However, should a second independent analysis yield incompatible results, then access to the original source code can help resolve those discrepancies.

But this is where the second complication arises: the technicalities of sharing source code are also non-trivial. There are obstacles that arise from the use of different platforms (Windows vs. Mac vs. Linux), or from issues such as missing external libraries or tacit assumptions about local directory structures. Ideally, therefore, the source code and data should be prepared in a manner that avoids such pernickety and annoying glitches.

http://www.psychonomic.org/featured-content-detail/go-check-ts-6b6-27c-transparent-workflow-tools-sci




Researchers from the United States Federal Reserve and the Department of the Treasury tried to replicate the results from 67 papers across 13 prestigious journals, but even after contacting authors when necessary, they were successful in only 49 per cent of cases where the data were not confidential and the researchers had the right software to analyse it.

the main reason for being unable to replicate findings was an inability to find the right data or the computer code that produced the original results, even after contacting the authors. Code was missing crucial functions, or certain variables were absent from the data, the paper says.

However, in nine cases for which the authors of the paper had the right dataset and code, they nonetheless got a different result or the code failed to finish executing

Is Economics Research Replicable? Sixty Published Papers fromThirteen Journals Say ”Usually Not”
http://www.federalreserve.gov/econresdata/feds/2015/files/2015083pap.pdf
http://theconversation.com/the-replication-crisis-has-engulfed-economics-49202


It finds that of the 24 empirical papers subjected to in-house replication review since September 2012, only four packages did not require any modifications. Most troubling, 14 packages (58%) had results in the paper that differed from those generated by the author’s own code.
http://journals.cambridge.org/action/displayAbstract?fromPage=online&aid=10269209&fileId=S1049096516000196



Beyond Bar and Line Graphs: Time for a New Data Presentation Paradigm
http://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1002128


Peer review openness initiative: http://opennessinitiative.org/PRO_Initiative_RSOS.pdf


# Alternatives
- Sweave: http://link.springer.com/chapter/10.1007/978-3-642-57489-4_89
	-> Example of irreproducible research: http://www.nature.com/nm/journal/v13/n11/full/nm1107-1276b.html
- RepoRts

- Matlab-tool for reproducible analyses: http://link.springer.com/article/10.3758%2Fs13428-015-0616-x

- kmr
- statTag: http://sites.northwestern.edu/stattag/
- StatWeave: http://homepage.divms.uiowa.edu/~rlenth/StatWeave/StatWeave-manual.pdf


# Abstract

papar: Create publication-ready manuscripts in R

Recently, growing attention has been drawn to the large number of scientific findings that are not reproducible.
One aspect of this worrisome state of affairs, which is not limited to the field of psychology, is non-reproducibility of statistical analyses and scientific computations.
Given that raw data are available, the reproducibility of analyses should be considered a minimum standard for judging scientific claims (Peng, 2011).
Two obvious reasons for non-reproducibility of analyses are (1) incorrect and (2) incomplete reporting of methods and statistics. 
A review of psychological journal articles found that 18% of the statistical results were reported incorrectly; these errors lead to incorrect inferences in 15% of surveyed articles (Bakker & Wicherts, 2011).
Dynamic documents that merge report and analysis scripts are an effective way to avoid erronenous statistics in manuscripts (Gandrud, 2013).
We introduce the R package 'papaja' that builds on the 'knitr' package allowing authors to use the easy-to-learn Markdown syntax to harness the typesetting-power of LaTeX.
papaja-functions additionally ensures that all necessary statistics are reported to ensure reproducibility and facilitate future synthesis of results.



J of the American Statistical Association appoints ‘reproducibility editors’ to assure code and data are shared https://t.co/BsdpwPtets





papaja: Create publication-ready manuscripts in R

Recently, growing attention has been drawn to the large number of scientific findings that are not reproducible.
One aspect of this worrisome state of affairs, which is not limited to the field of psychology, is non-reproducibility of statistical analyses and scientific computations.
Given that raw data are available, the reproducibility of analyses should be considered a minimum standard for judging scientific claims (Peng, 2011).
Two obvious reasons for non-reproducibility of analyses are incorrect and incomplete reporting of methods and statistics.
A review of psychological journal articles found that 18% of the statistical results were reported incorrectly; these errors lead to incorrect inferences in 15% of surveyed articles (Bakker & Wicherts, 2011).
Dynamic documents that merge reports and analysis scripts are an effective way to avoid erroneous statistical reporting (Gandrud, 2013).
We introduce 'papaja', a package for the R Statistical Environment (R Core Team, 2014) that provides a framework to create dynamic documents that adhere to APA guidelines.
papaja is tailored to the needs of experimental psychologists: we supply convenience functions to report commonly used statistics in accordance with APA guidelines and in a way that ensures reproducibility of analyses and facilitates future synthesis of results.

-->

<!-- https://twitter.com/HermanAguinis/status/859843021575245825 -->


R Markdown has been suggested as one possible framework for reproducible analyses [@R-rmarkdown].
`papaja` is a R-package in the making including a [R Markdown](http://rmarkdown.rstudio.com/) template that can be used with (or without) [RStudio](http://www.rstudio.com/) to produce documents, which conform to the American Psychological Association (APA) manuscript guidelines (6th Edition).
The package uses the \LaTeX document class [apa6](http://www.ctan.org/pkg/apa6) and a .docx-reference file, so you can create PDF documents, or Word documents if you have to.
Moreover, `papaja` supplies R-functions that facilitate reporting results of your analyses in accordance with APA guidelines.

Markdown is a simple formatting syntax that can be used to author HTML, PDF, and MS Word documents (among others).
In the following I will assume you have hopped onto the band wagon and know how to use R Markdown to conduct and comment your analyses.
If this is not the case, I recommend you get to grips with [R Markdown](http://rmarkdown.rstudio.com/) first.
I use [RStudio](http://www.rstudio.com/) (which makes use of [pandoc](http://johnmacfarlane.net/pandoc/)) to create my documents, but the general process works using any other text editor.

Although LaTeX is widely used to write entire manuscripts (not just equations), it is not commonly used in the field of psychology.
We suspect that the neglect is largely due to its complexity and shallow learning curve.
Both appear to outweigh the advantages of the system when it comes to handling citations and cross-references or typesetting large documents, complex tables, and equations.
Markdown paired with `pandoc` provides a simple interface to harness the power of LaTeX without requiring in-depth knowledge about LaTeX (see [Document compilation]).


## Implementation

*In this section we provide a quick overview of the software and the underlying design principles.
Unless you are interested in these details it's safe to skip this section.*

### Guiding principles
In our development of this package our design decisions are based on two guiding principles:

1. **`papaja` documents are convertible**.
A central motivation for the development of the package was the experience that many (if not most) scientific journals in psychology require that the final version of a submitted manuscript be provided as a Microsoft Word or RTF document.
We, thus, strive to employ solutions that work for both LaTeX and Word output formats even if it means that some of the functions are less versatile than they could be.

2. **`papaja` does not compute**.
The package is meant to facilitate writing reports and manuscripts in APA style; it is *not* meant to analyse data.
Functions provided in this package do as little computing as possible to grant authors maximal analytic flexibility.
Moreover, limiting the amount of computing done by the package facilitates package maintenance.

While we are guided by these principles, they are guidelines rather than commandments and we deviate from them if necessary.
For example, `papaja` functions do compute statistics that should be routinely reported according to APA guidelines, such as confidence intervals, if they are not provided in the analysis output objects.
We, however, try to enable customization and replacement of these defaults whenever we can.


### Document compilation
It is important to note that `papaja` builds on several existing R packages, which in turn build on other software, to compile the final document.
This layered software design grants the package its capabilities but it comes at a cost:
When compilation of a `papaja`-document throws an error it may not be immediately obvious to an inexperienced user, which part of the process failed.
We, thus, provide an overview of the compilation process and the software involved.

The compilation process is outlined in Figure \@ref(fig:compilation-process-diagram).
As detailed in the [R Markdown components] section, an R Markdown document consists of three components:
A YAML front matter that contains document meta data, prose written in markdown (and optionally LaTeX) syntax, and R code in so-called *code chunks*.

Additionally, the R code contained in an R Markdown document usually accesses data that are either stored in a file on the computers hard drive or a database on the local network or internet.
When the document is compiled either by calling `rmarkdown::render()` or by clicking the Knit-button in RStudio, the YAML front matter is parsed.
Errors during this processing step are usually due to erroneous YAML syntax and start with  `Error in yaml::yaml.load(enc2utf8(string), ...) :`.
Next, the R code inside the R Markdown document is executed sequentially from top to bottom of the document and the resulting output is inserted into the document in markdown syntax.
Any figures that are generated during the execution of the R code are stored to the hard drive and embedded into the markdown document.
The R code is executed in a new R session with an empty workspace, no attached packages, and with the working directory set to the path of the R Markdown file.
If any portion of the R code throws an error the compilation is aborted.
In RStudio the debugger will point to the first line of the R code chunk that threw the error---not the exact line responsible for the error---and report the error message.
R error messages usually start with `Error:`, for example, `Error: Object 'experiment_data' not found.`

```{r compilation-process-diagram, fig.cap = "Process diagram illustrating the compilation of reproducible reports written with `papaja`. Boxes represent input files, diamonds represent compiling software, and ovals represent output files. Dashed components are either implicit (components of R Markdown files) or by default deleted after the compilation and, thus, invisible to the user.", fig.align = "center", fig.height = 7, echo = FALSE}
# grViz("
# digraph software_process {
#   graph [rankdir = TB, fontname = Helvetica, ranksep = 0.8, overlap = FALSE]
# 
#   node [shape = box, fontname = Helvetica]
# 
#   # Input
#   node [margin = 0.2]
#   
#   subgraph cluster_0 {
#     yaml [label = 'Meta_data.yaml', style = 'dashed']
#     prose [label = 'Prose.md', style = 'dashed']
#     code [label = 'Code.R', style = 'dashed']
# 
#     label = 'Manuscript.Rmd'
#   }
# 
#   data [label = 'Data.csv']
#   references [label = 'References.bib']
# 
#   # Output
#   node [shape = oval, style = dashed, margin = 0.1]
#   markdown [label = 'Manuscript.md']
# 
#   node[style = solid]
#   figure [label = 'Figure.eps']
#   tex [label = 'Manuscript.tex']
#   pdf [label = 'Manuscript.pdf']
#   docx [label = 'Manuscript.docx']
# 
#   # Software
#   node [shape = diamond]
#   r [label = 'R']
#   pandoc [label = 'pandoc']
#   latex [label = 'LaTeX']
# 
#   # Transitions
#   edge [fontname = Helvetica, fontsize = 12, arrowhead = vee]
# 
#   {code data} -> r
#   r -> r [label = 'papaja\nbookdown\n&nbsp;&nbsp;rmarkdown\nknitr']
#   r -> {markdown figure}
#   {yaml prose} -> markdown
# 
#   {markdown figure references} -> pandoc
#   pandoc -> pandoc [label = 'papaja\n&nbsp;&nbsp;pandoc-citeproc']
#   pandoc -> tex -> latex -> pdf
#   pandoc -> docx
#   latex -> latex [label = '&nbsp;apa6']
# 
#   {rank = same; pdf; docx}
# }
# ")

knitr::include_graphics("compilation_process.png")
```

After the R code has been executed the `bookdown` document format `pdf_document2()` or `word_document2()`, respectively, provides functions that enable the cross-referencing syntax `\@ref()` described in the [Cross-referencing] section.
Incorrect use of the cross-referencing syntax typically does not interfere with the document compilation but is apparent from missing or incorrect cross-references in the compiled document, e.g. instead of a figure number the document may contain the figure handle such as `(#fig:my-figure)`.
The result of this processing step is a pure markdown document containing only a YAML header, prose in markdown (and optionally LaTeX) syntax and rendered images in PDF, EPS, PNG, and TIFF formats at 300 dpi as set by `apa6_pdf()` or `apa6_word()`, respectively.

The markdown document, images and an optional BiB(La)TeX file that contains bibliographic information are the input to the next processing step.
`rmarkdown::render()` assembles a system call to pandoc that is supplemented by `papaja` to include a call to an additional filter and can be further customized by the user.
pandoc parses the contents of the markdown file and translates it into an abstract syntax tree (AST).
The `pandoc-citeproc` filter is than applied to the AST to replace the citation markup by the citation text and insert a reference section.
As detailed in the [Citations] section, `pandoc-citeproc` relies on the [citation styles language](http://citationstyles.org/) (CSL), an XML-based specification of citation and bibliography formatting rules.
Unfortunately, CSL does not support in-text citations.
To overcome this limitation, `pandoc-citeproc` provides a separate syntax for in-text citations, which is based on the same CSL style.
As a result the CSL APA6 style uses ampersands for all citations, including in-text citations, defying the APA citation style.
That is why `papaja` provides an additional R-based filter that is applied to the AST to replace ampersands in in-text citations with the word *and*.

After all filters have been applied to the AST pandoc converts the document into the target output format, that is, PDF or DOCX.
To create DOCX-documents `papaja` provides a reference DOCX-file containing page setup and style definitions that pandoc uses to create the manuscript file.
That is, pandoc translates the AST directly to the office open XML format.
To create PDF-documents pandoc in turn relies on LaTeX, that is, pandoc translates the AST to a TeX-file based on a template provided by `papaja`.
This template invokes the `apa6` LaTeX document class [@???] and loads several additional LaTeX packages.
pandoc then generates a system call to LaTeX to render the PDF document.
During this processing step, that is, following the pandoc system calls, errors are due to failures of LaTeX to compile the TeX-file and usually start with `!`, for example, `! Undefined control sequence.` or `! Missing $ inserted`.

- YAML front matter is read
    - `Error in yaml::yaml.load(enc2utf8(string), ...) :`
- R code is executed
    - `Error: Object 'experiment_data' not found.`
    - Gives first line of erroneous R code chunk
- `bookdown` adds cross- and text-references
    - No error messages; look for `(#fig:chunk-name)` in text
    - Don't use `_` in chunk names!
- `pandoc` and `pandoc-citeproc` convert Markdown
    - `Error: pandoc document conversion failed with error 1`
    - `pandoc-citeproc: Cannot decode byte '\xfc'`
    - `pandoc-citeproc: reference XYZ not found`,<br />shows up as **???** in text
- LaTeX creates a PDF
    - `! Missing $ inserted`


## Alternatives

Needless to say, not all journals require manuscripts to be prepared according to APA guidelines.
Other journal templates for the `rmarkdown` package are available in the [`rticles`](https://github.com/rstudio/rticles) package.
It includes a set of templates for authoring of R related journal and conference submissions.

- papeR
- reportR & apaStyle
- Sweave
- schoRsch [@pfister_schorsch:_2016]
- sigr


## Getting started

### Software requirements

`papaja` depends on additional software, namely,

@. [R](http://www.r-project.org/) 2.11.1 or later and
@. [pandoc](http://johnmacfarlane.net/pandoc/) 1.19 or later

If you work with [RStudio](http://www.rstudio.com/) (1.1.453 or later) pandoc should already be installed, otherwise refer to the [installation instructions](http://pandoc.org/installing.html) for your operating system.

#### Setting up a TeX distribution

If you want to create PDF- in addition to DOCX-documents you additionally need

@. [TeX](http://de.wikipedia.org/wiki/TeX) 2013 or later.

If you have no use for TeX beyond rendering R Markdown documents, I recommend you use [TinyTex](https://yihui.name/tinytex/). 
Otherwise consider [MikTeX](http://miktex.org/) for Windows, [MacTeX](https://tug.org/mactex/) for Mac, or [TeX Live](http://www.tug.org/texlive/) for Linux.
TinyTex can be installed from within R as follows.

```{r eval = FALSE}
if(!"tinytex" %in% rownames(installed.packages())) install.packages("tinytex")

tinytex::install_tinytex()
```

`papaja` requires additional $\LaTeX$ packages that are not part of the basic TeX installations.
When using TinyTex, the required packages will be installed automatically when rendering a the first PDF-document.
Users of other TeX distribution need to take one of the following additional steps.
MikTeX users may enable the [automatic installation of missing packages](https://miktex.org/howto/miktex-console).
If you are comfortable using the command line, it may be convenient to run the following command.

~~~bash
initexmf --set-config-value [MPM]AutoInstall=1
~~~

```{r latex-packages, echo = FALSE}
latex_packages <- c("apa6", "etoolbox", "booktabs", "threeparttable", "caption", "fancyhdr", "endfloat", "upquote", "microtype", "threeparttablex", "environ", "trimspaces", "url", "csquotes", "was", "lineno", "pgf", "ms", "xcolor", "mptopdf", "txfonts", "sttools", "fancyvrb", "framed", "parskip")
latex_packages <- latex_packages[order(latex_packages)]
```

<!-- <details> -->
<!-- <summary>Show list of required $\LaTeX$ packages</summary> -->

<!-- ~~~ -->
<!-- `r paste0(latex_packages, collapse = "\n")` -->
<!-- ~~~ -->
<!-- </details> -->

This option is not available in MacTeX or TeX Live.
Alternatively, you can install the additional packages manually.
Again the installation can be done conveniently from the command line.
MikTeX users can run the following command.

~~~bash
mpm --install=`r paste0(latex_packages, collapse = ",")`
~~~

It may be necessary to launch MikTeX console as administrator (right-click and *Run as administrator*) before executing the command.

TeXLive and MacTeX users can run the following command.

~~~sh
tlmgr install `r paste0(latex_packages, collapse = " ")`
~~~

It may be necessary to first install `tlmgr`.
Alternatively, Ubuntu users can install the following Ubuntu packages:

~~~sh
sudo apt-get install texlive-publishers texlive-fonts-extra texlive-latex-extra texlive-humanities lmodern
~~~

Finally, you may [install a *complete*](https://tex.stackexchange.com/a/105650/11001)---not the basic---TeX distribution that comes with all available LaTeX packages but is several gigabytes large.


### Installing papaja
`papaja` is not yet available on CRAN but you can install it from GitHub:

```{r install_papapja, eval = FALSE}
# Install devtools package if necessary
if(!"devtools" %in% rownames(installed.packages())) install.packages("devtools")

# Install the stable development verions from GitHub
devtools::install_github("crsh/papaja")

# Install the latest development snapshot from GitHub
devtools::install_github("crsh/papaja@devel")
```

`r not_on_cran`

### Creating a document

Once you have installed `papaja` and all other [required software][Software requirements], the APA manuscript template is available through the RStudio menus when creating a new R Markdown file, Figure  \@ref(fig:template-selection).

```{r template-selection, echo = FALSE, fig.cap = "papaja's APA6 template is available through the RStudio menues."}
knitr::include_graphics("https://raw.githubusercontent.com/crsh/papaja/master/inst/images/template_selection.png")
```

When you click RStudio's *Knit* button (Figure \@ref(fig:knit-button)) `papaja`, `rmarkdown,` and `knitr` work together to create an APA conform manuscript that includes both your manuscript text and the results of any embedded R code.

```{r knit-button, echo = FALSE, fig.cap = "The *Knit* button in the RStudio."}
knitr::include_graphics("https://raw.githubusercontent.com/crsh/papaja/master/inst/images/knitting.png")
```


If you don't use RStudio, you can achieve the same result via the R command line.
Use `rmarkdown::draft()` to create a new R Markdown file and `rmarkdown::render()` to render the document.

```{r new_document, eval = FALSE}
# Create new R Markdown file
rmarkdown::draft(
  "mymanuscript.Rmd"
  , "apa6"
  , package = "papaja"
  , create_dir = FALSE
  , edit = FALSE
)

# Render manuscript
rmarkdown::render("mymanuscript.Rmd")
```

---




`papaja` is a R-package in the making including a [R Markdown](http://rmarkdown.rstudio.com/) template that can be used with (or without) [RStudio](http://www.rstudio.com/) to produce documents, which conform to the American Psychological Association (APA) manuscript guidelines (6th Edition). The package uses the LaTeX document class [apa6](http://www.ctan.org/pkg/apa6) and a .docx-reference file, so you can create PDF documents, or Word documents if you have to. Moreover, `papaja` supplies R-functions that facilitate reporting results of your analyses in accordance with APA guidelines.


```{block2, type='rmdimportant'}
Because **knitr** does not allow duplicate chunk labels in a source document, you need to make sure there are no duplicate labels in your book chapters, otherwise **knitr** will signal an error when knitting the merged Rmd file. 
```
